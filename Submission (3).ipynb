{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "    time.sleep(3)\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    table = soup.find(\"table\",{\"class\":\"wikitable sortable jquery-tablesorter\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "    rows.pop(0)\n",
    "\n",
    "    for row in rows:\n",
    "        data = list()\n",
    "        data = row.text.split(\"\\n\")\n",
    "        if len(data)>3:\n",
    "            data.pop(0)\n",
    "            data.pop()\n",
    "            data.pop()\n",
    "        if len(data)==5:\n",
    "            print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "    #Goto Fixtures    \n",
    "    browser.find_element_by_link_text(\"Fixtures\").click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "    div = soup.find(\"div\",{\"class\":\"js-list\"})\n",
    "    anchors = div.find_all(\"a\")\n",
    "\n",
    "    for a in anchors:\n",
    "        data = []\n",
    "        try:\n",
    "            match_title = soup.find(\"strong\",{\"class\":\"fixture__name fixture__name--with-margin\"}).text\n",
    "            match_series = soup.find(\"span\",{\"class\":\"u-unskewed-text fixture__tournament-label u-truncated\"}).text\n",
    "            place = soup.find(\"p\",{\"class\":\"fixture__additional-info\"}).text\n",
    "            date = soup.find(\"span\",{\"class\":\"fixture__date\"}).text\n",
    "            timing = soup.find(\"span\",{\"class\":\"fixture__time\"}).text\n",
    "            \n",
    "            data.append(match_title)\n",
    "            data.append(match_series)\n",
    "            data.append(place)\n",
    "            data.append(date)\n",
    "            data.append(timing)\n",
    "\n",
    "            print(data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.guru99.com/\")\n",
    "\n",
    "    #Goto Selenium\n",
    "    browser.find_element_by_link_text(\"Selenium\").click()\n",
    "\n",
    "    #Goto exception handling topic\n",
    "    xpath = '//a[@title = \"Selenium Exception Handling (Common Exceptions List)\"]'\n",
    "    browser.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    table = soup.find(\"table\",{\"class\":\"table table-striped\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        print(row.text)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"http://statisticstimes.com/\")\n",
    "    browser.get(\"http://statisticstimes.com/economy/india-statistics.php\")\n",
    "\n",
    "    xpath = '/html/body/div[2]/div[2]/div[2]/ul/li[1]'\n",
    "    browser.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\",{\"id\":\"table_id\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "    rows.pop(0)\n",
    "    rows.pop(0)\n",
    "\n",
    "    for i, row in enumerate(rows, start = 1):\n",
    "        try:\n",
    "            row = row.text.split(\"\\n\")\n",
    "            rank = i\n",
    "            if(i>9):\n",
    "                state = row[0][2:]\n",
    "            else:\n",
    "                state = row[0][1:]\n",
    "            gsdp_19_20 = row[1]\n",
    "            gsdp_18_19 = row[2]\n",
    "            share = row[3]\n",
    "            gdp = row[4]\n",
    "            print(rank, state, gsdp_19_20, gsdp_18_19, share, gdp)\n",
    "            print()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://github.com/\")\n",
    "\n",
    "    #Goto trending by first clicking on Explore tab and then click Trending\n",
    "    xpath = '//summary[@class=\"HeaderMenu-summary HeaderMenu-link px-0 py-3 border-0 no-wrap d-block d-lg-inline-block\"]'\n",
    "    browser.find_elements_by_xpath(xpath)[1].click()\n",
    "    time.sleep(2)\n",
    "    browser.find_element_by_link_text(\"Trending\").click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    articles = soup.find_all(\"article\", {\"class\":\"Box-row\"})\n",
    "\n",
    "    for article in articles:\n",
    "        try:\n",
    "            repo_title = article.find(\"h1\").text.split(\"/\")[1].strip()\n",
    "        except:\n",
    "            repo_title = \"\"\n",
    "\n",
    "        try:\n",
    "            repo_des = article.find(\"p\").text.strip()\n",
    "        except:\n",
    "            repo_des = \"\"\n",
    "\n",
    "        try:\n",
    "            contri_count = article.find(\"span\",{\"class\":\"d-inline-block mr-3\"})\n",
    "            contri_count = len(contri_count.find_all(\"a\"))\n",
    "        except:\n",
    "            contri_count = 1\n",
    "\n",
    "        try:\n",
    "            languages = article.find(\"span\",{\"itemprop\":\"programmingLanguage\"}).text.strip()\n",
    "        except:\n",
    "            languages = \"\"\n",
    "\n",
    "        print(repo_title, repo_des, contri_count, languages)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.billboard.com/\")\n",
    "    browser.find_element_by_link_text(\"CHARTS\").click()\n",
    "    browser.find_element_by_link_text(\"Hot 100\").click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    ol = soup.find(\"ol\",{\"class\":\"chart-list__elements\"})\n",
    "    lis = ol.find_all(\"li\")\n",
    "\n",
    "    for li in lis:\n",
    "        try:\n",
    "            name = li.find(\"span\",{\"class\":\"chart-element__information__song text--truncate color--primary\"}).text.strip()\n",
    "        except:\n",
    "            name = \"\"\n",
    "\n",
    "        try:   \n",
    "            artist = li.find(\"span\",{\"class\":\"chart-element__information__artist text--truncate color--secondary\"}).text.strip()\n",
    "        except:\n",
    "            artist = \"\"\n",
    "        \n",
    "        try:\n",
    "            last_week = li.find(\"div\",{\"class\":\"chart-element__meta text--center color--secondary text--last\"}).text.strip()\n",
    "        except:\n",
    "            last_week = \"\"\n",
    "\n",
    "        try:\n",
    "            peak_rank = li.find(\"div\",{\"class\":\"chart-element__meta text--center color--secondary text--peak\"}).text.strip()\n",
    "        except:\n",
    "            peak_rank = \"\"\n",
    "\n",
    "        try:\n",
    "            weeks_on_board = li.find(\"div\",{\"class\":\"chart-element__meta text--center color--secondary text--week\"}).text.strip()\n",
    "        except:\n",
    "            weeks_on_board = \"\"\n",
    "\n",
    "        print(name, artist, last_week, peak_rank, weeks_on_board)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.naukri.com/\")\n",
    "    wait = WebDriverWait(browser, 600)\n",
    "\n",
    "    #Goto recruiters tab\n",
    "    xpath = '//*[@id=\"root\"]/div[1]/div/ul[1]/li[2]/a/div'\n",
    "    browser.find_element_by_xpath(xpath).click()\n",
    "\n",
    "    #Goto the active tab\n",
    "    window_name = browser.window_handles[1]\n",
    "    browser.switch_to.window(window_name=window_name)\n",
    "\n",
    "    #Search for Data Science in search box\n",
    "    xpath = '//*[@class=\"sugInp\"]'\n",
    "    search_box = wait.until(ec.element_to_be_clickable((By.XPATH, xpath)))\n",
    "    search_box.send_keys(\"Data Science\"+Keys.ENTER)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    divs = soup.find_all(\"div\",{\"class\":\"recInfo\"})\n",
    "\n",
    "    for div in divs:\n",
    "        para = div.find(\"p\",{\"class\":\"highlightable\"}).text.strip()\n",
    "        skills = div.find(\"div\",{\"class\":\"hireSec highlightable\"}).text.strip()\n",
    "        print(para)\n",
    "        print(skills)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    table = soup.find(\"table\",{\"class\":\"in-article sortable\"})\n",
    "    rows = table.find_all(\"tr\")\n",
    "    #Delete header row\n",
    "    rows.pop(0)\n",
    "    rows.pop(0)\n",
    "\n",
    "    for row in rows:\n",
    "        row = row.text.split(\"\\n\")\n",
    "\n",
    "        book = row[2]\n",
    "        author = row[3]\n",
    "        volumes_sold = row[4]\n",
    "        publisher = row[5]\n",
    "        genre = row[6]\n",
    "\n",
    "        print(book)\n",
    "        print(author)\n",
    "        print(volumes_sold)\n",
    "        print(publisher)\n",
    "        print(genre)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    divs = soup.find_all(\"div\",{\"class\":\"lister-item-content\"})\n",
    "\n",
    "    for div in divs:\n",
    "        div = div.text.split(\"\\n\")\n",
    "        div = [d for d in div if len(d)>1]\n",
    "        name = div[1]\n",
    "        year_span = div[2]\n",
    "        genre = div[5]\n",
    "        run_time = div[4]\n",
    "        ratings = div[6]\n",
    "        votes = div[-1]\n",
    " \n",
    "        print(name)\n",
    "        print(year_span)\n",
    "        print(genre)\n",
    "        print(run_time)\n",
    "        print(ratings)\n",
    "        print(votes)\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(\"https://archive.ics.uci.edu/\")\n",
    "    time.sleep(5)\n",
    "    browser.find_element_by_link_text(\"View ALL Data Sets\").click()\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    table = soup.find(\"table\",{\"border\":1,\"cellpadding\":5})\n",
    "\n",
    "    rows = table.find_all(\"tr\")\n",
    "    #Delete header row\n",
    "    rows.pop(0)\n",
    "\n",
    "    for row in rows:\n",
    "        row = row.text.strip()\n",
    "        with open(\"Q10-result.txt\",\"a+\") as fh:\n",
    "            fh.write(row+\"\\n\\n\\n\")\n",
    "        print(\"Saved the output in Q10-result.txt file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
